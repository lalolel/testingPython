{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Basics Guide\n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library for Python. It provides data structures like Series and DataFrame that make working with structured data intuitive and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This guide covers the fundamental operations in Pandas for data manipulation and analysis. Key takeaways:\n",
    "\n",
    "- **DataFrames** are the core data structure for structured data\n",
    "- **Indexing and filtering** allow precise data selection\n",
    "- **GroupBy operations** enable powerful aggregations and insights\n",
    "- **Data cleaning** functions handle missing values and data quality\n",
    "- **Merging and reshaping** combine and transform datasets\n",
    "- **String and datetime operations** handle text and temporal data\n",
    "\n",
    "Practice with these examples and explore the extensive Pandas documentation for more advanced features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series from list\n",
    "series1 = pd.Series([1, 2, 3, 4, 5])\n",
    "print(\"Series from list:\")\n",
    "print(series1)\n",
    "\n",
    "# Series with custom index\n",
    "series2 = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "print(\"\\nSeries with custom index:\")\n",
    "print(series2)\n",
    "\n",
    "# Series from dictionary\n",
    "series3 = pd.Series({'apple': 3, 'banana': 2, 'orange': 5})\n",
    "print(\"\\nSeries from dictionary:\")\n",
    "print(series3)\n",
    "\n",
    "# Series properties\n",
    "print(f\"\\nSeries shape: {series1.shape}\")\n",
    "print(f\"Series dtype: {series1.dtype}\")\n",
    "print(f\"Series index: {series2.index.tolist()}\")\n",
    "print(f\"Series values: {series2.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'Age': [25, 30, 35, 28],\n",
    "    'City': ['New York', 'London', 'Tokyo', 'Paris'],\n",
    "    'Salary': [50000, 60000, 55000, 52000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame from dictionary:\")\n",
    "print(df)\n",
    "\n",
    "# DataFrame from list of lists\n",
    "data_list = [['Alice', 25, 'New York'], ['Bob', 30, 'London'], ['Charlie', 35, 'Tokyo']]\n",
    "df2 = pd.DataFrame(data_list, columns=['Name', 'Age', 'City'])\n",
    "print(\"\\nDataFrame from list of lists:\")\n",
    "print(df2)\n",
    "\n",
    "# DataFrame with custom index\n",
    "df3 = pd.DataFrame(data, index=['emp1', 'emp2', 'emp3', 'emp4'])\n",
    "print(\"\\nDataFrame with custom index:\")\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DataFrame Properties and Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic properties\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"DataFrame size: {df.size}\")\n",
    "print(f\"DataFrame columns: {df.columns.tolist()}\")\n",
    "print(f\"DataFrame index: {df.index.tolist()}\")\n",
    "print(f\"DataFrame dtypes:\\n{df.dtypes}\")\n",
    "\n",
    "# Quick overview\n",
    "print(\"\\nDataFrame info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nDataFrame description:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger dataset for examples\n",
    "np.random.seed(42)\n",
    "large_df = pd.DataFrame({\n",
    "    'A': np.random.randn(100),\n",
    "    'B': np.random.randint(1, 100, 100),\n",
    "    'C': np.random.choice(['X', 'Y', 'Z'], 100),\n",
    "    'D': pd.date_range('2023-01-01', periods=100)\n",
    "})\n",
    "\n",
    "# View first and last rows\n",
    "print(\"First 5 rows:\")\n",
    "print(large_df.head())\n",
    "\n",
    "print(\"\\nLast 3 rows:\")\n",
    "print(large_df.tail(3))\n",
    "\n",
    "# Sample random rows\n",
    "print(\"\\nRandom 3 rows:\")\n",
    "print(large_df.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Selecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select single column\n",
    "print(\"Select 'Name' column:\")\n",
    "print(df['Name'])\n",
    "\n",
    "# Select multiple columns\n",
    "print(\"\\nSelect multiple columns:\")\n",
    "print(df[['Name', 'Age']])\n",
    "\n",
    "# Select rows by index\n",
    "print(\"\\nSelect first 2 rows:\")\n",
    "print(df.iloc[0:2])\n",
    "\n",
    "# Select rows by label (if custom index)\n",
    "print(\"\\nSelect by label (custom index):\")\n",
    "print(df3.loc['emp1':'emp2'])\n",
    "\n",
    "# Select specific cells\n",
    "print(\"\\nSelect specific cell:\")\n",
    "print(df.iloc[0, 1])  # First row, second column\n",
    "print(df.loc[0, 'Age'])  # Row 0, 'Age' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean filtering\n",
    "print(\"People older than 28:\")\n",
    "older_than_28 = df[df['Age'] > 28]\n",
    "print(older_than_28)\n",
    "\n",
    "# Multiple conditions\n",
    "print(\"\\nPeople older than 25 and salary > 52000:\")\n",
    "filtered = df[(df['Age'] > 25) & (df['Salary'] > 52000)]\n",
    "print(filtered)\n",
    "\n",
    "# Filter by string contains\n",
    "print(\"\\nPeople from cities containing 'o':\")\n",
    "city_filter = df[df['City'].str.contains('o')]\n",
    "print(city_filter)\n",
    "\n",
    "# Filter by list of values\n",
    "print(\"\\nPeople from New York or London:\")\n",
    "city_list = df[df['City'].isin(['New York', 'London'])]\n",
    "print(city_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Adding and Modifying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to avoid modifying original\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Add new column\n",
    "df_copy['Department'] = ['IT', 'Finance', 'Marketing', 'HR']\n",
    "print(\"DataFrame with new column:\")\n",
    "print(df_copy)\n",
    "\n",
    "# Add calculated column\n",
    "df_copy['Salary_Bonus'] = df_copy['Salary'] * 1.1\n",
    "print(\"\\nWith calculated column:\")\n",
    "print(df_copy[['Name', 'Salary', 'Salary_Bonus']])\n",
    "\n",
    "# Modify existing values\n",
    "df_copy.loc[0, 'Age'] = 26\n",
    "print(\"\\nAfter modifying Alice's age:\")\n",
    "print(df_copy[['Name', 'Age']])\n",
    "\n",
    "# Add new row\n",
    "new_row = {'Name': 'Eve', 'Age': 32, 'City': 'Berlin', 'Salary': 58000, 'Department': 'Sales', 'Salary_Bonus': 63800}\n",
    "df_copy = pd.concat([df_copy, pd.DataFrame([new_row])], ignore_index=True)\n",
    "print(\"\\nAfter adding new row:\")\n",
    "print(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sorting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by single column\n",
    "print(\"Sorted by Age (ascending):\")\n",
    "print(df.sort_values('Age'))\n",
    "\n",
    "# Sort by single column (descending)\n",
    "print(\"\\nSorted by Salary (descending):\")\n",
    "print(df.sort_values('Salary', ascending=False))\n",
    "\n",
    "# Sort by multiple columns\n",
    "print(\"\\nSorted by Age then Salary:\")\n",
    "print(df.sort_values(['Age', 'Salary']))\n",
    "\n",
    "# Sort by index\n",
    "print(\"\\nSorted by index (descending):\")\n",
    "print(df.sort_index(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with duplicate categories\n",
    "sales_data = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B'],\n",
    "    'Region': ['North', 'South', 'North', 'East', 'South', 'West', 'East', 'North'],\n",
    "    'Sales': [100, 150, 120, 200, 180, 90, 160, 140],\n",
    "    'Quantity': [10, 15, 12, 20, 18, 9, 16, 14]\n",
    "})\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales_data)\n",
    "\n",
    "# Group by single column\n",
    "print(\"\\nGrouped by Product (sum):\")\n",
    "print(sales_data.groupby('Product').sum())\n",
    "\n",
    "# Group by multiple columns\n",
    "print(\"\\nGrouped by Product and Region:\")\n",
    "print(sales_data.groupby(['Product', 'Region']).sum())\n",
    "\n",
    "# Different aggregation functions\n",
    "print(\"\\nVarious aggregations by Product:\")\n",
    "print(sales_data.groupby('Product').agg({\n",
    "    'Sales': ['sum', 'mean', 'count'],\n",
    "    'Quantity': ['min', 'max']\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Missing Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with missing values\n",
    "data_with_na = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [10, np.nan, 30, 40, np.nan],\n",
    "    'C': ['x', 'y', 'z', np.nan, 'w']\n",
    "})\n",
    "\n",
    "print(\"DataFrame with missing values:\")\n",
    "print(data_with_na)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(data_with_na.isnull().sum())\n",
    "\n",
    "# Fill missing values\n",
    "print(\"\\nFill NaN with 0:\")\n",
    "print(data_with_na.fillna(0))\n",
    "\n",
    "print(\"\\nFill NaN with column mean (numeric only):\")\n",
    "filled_mean = data_with_na.fillna(data_with_na.mean(numeric_only=True))\n",
    "print(filled_mean)\n",
    "\n",
    "# Drop rows with missing values\n",
    "print(\"\\nDrop rows with any NaN:\")\n",
    "print(data_with_na.dropna())\n",
    "\n",
    "# Drop columns with missing values\n",
    "print(\"\\nDrop columns with any NaN:\")\n",
    "print(data_with_na.dropna(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String data\n",
    "text_data = pd.DataFrame({\n",
    "    'Names': ['john doe', 'JANE SMITH', 'Bob Johnson', 'alice brown'],\n",
    "    'Emails': ['john@email.com', 'jane@company.org', 'bob@test.net', 'alice@site.edu']\n",
    "})\n",
    "\n",
    "print(\"Original text data:\")\n",
    "print(text_data)\n",
    "\n",
    "# String methods\n",
    "print(\"\\nUppercase names:\")\n",
    "print(text_data['Names'].str.upper())\n",
    "\n",
    "print(\"\\nTitle case names:\")\n",
    "print(text_data['Names'].str.title())\n",
    "\n",
    "print(\"\\nString length:\")\n",
    "print(text_data['Names'].str.len())\n",
    "\n",
    "# Extract domain from email\n",
    "print(\"\\nEmail domains:\")\n",
    "print(text_data['Emails'].str.split('@').str[1])\n",
    "\n",
    "# String contains\n",
    "print(\"\\nNames containing 'o':\")\n",
    "print(text_data[text_data['Names'].str.contains('o')])\n",
    "\n",
    "# Replace strings\n",
    "print(\"\\nReplace 'john' with 'John':\")\n",
    "print(text_data['Names'].str.replace('john', 'John'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Date and Time Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date data\n",
    "date_data = pd.DataFrame({\n",
    "    'Date_String': ['2023-01-15', '2023-02-20', '2023-03-25', '2023-04-30'],\n",
    "    'Sales': [1000, 1200, 800, 1500]\n",
    "})\n",
    "\n",
    "# Convert string to datetime\n",
    "date_data['Date'] = pd.to_datetime(date_data['Date_String'])\n",
    "print(\"DataFrame with datetime:\")\n",
    "print(date_data)\n",
    "print(f\"\\nDate column dtype: {date_data['Date'].dtype}\")\n",
    "\n",
    "# Extract date components\n",
    "date_data['Year'] = date_data['Date'].dt.year\n",
    "date_data['Month'] = date_data['Date'].dt.month\n",
    "date_data['Day'] = date_data['Date'].dt.day\n",
    "date_data['Weekday'] = date_data['Date'].dt.day_name()\n",
    "\n",
    "print(\"\\nWith extracted date components:\")\n",
    "print(date_data[['Date', 'Year', 'Month', 'Day', 'Weekday']])\n",
    "\n",
    "# Date range\n",
    "print(\"\\nDate range:\")\n",
    "date_range = pd.date_range('2023-01-01', '2023-01-10', freq='D')\n",
    "print(date_range)\n",
    "\n",
    "# Time series data\n",
    "ts_data = pd.DataFrame({\n",
    "    'Date': pd.date_range('2023-01-01', periods=10, freq='D'),\n",
    "    'Value': np.random.randn(10)\n",
    "})\n",
    "ts_data.set_index('Date', inplace=True)\n",
    "print(\"\\nTime series data:\")\n",
    "print(ts_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Merging and Joining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "employees = pd.DataFrame({\n",
    "    'emp_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'dept_id': [10, 20, 10, 30]\n",
    "})\n",
    "\n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': [10, 20, 30, 40],\n",
    "    'dept_name': ['IT', 'Finance', 'HR', 'Marketing']\n",
    "})\n",
    "\n",
    "print(\"Employees:\")\n",
    "print(employees)\n",
    "print(\"\\nDepartments:\")\n",
    "print(departments)\n",
    "\n",
    "# Inner join\n",
    "print(\"\\nInner join:\")\n",
    "inner_join = pd.merge(employees, departments, on='dept_id')\n",
    "print(inner_join)\n",
    "\n",
    "# Left join\n",
    "print(\"\\nLeft join:\")\n",
    "left_join = pd.merge(employees, departments, on='dept_id', how='left')\n",
    "print(left_join)\n",
    "\n",
    "# Concatenate DataFrames\n",
    "more_employees = pd.DataFrame({\n",
    "    'emp_id': [5, 6],\n",
    "    'name': ['Eve', 'Frank'],\n",
    "    'dept_id': [20, 10]\n",
    "})\n",
    "\n",
    "print(\"\\nConcatenated DataFrames:\")\n",
    "all_employees = pd.concat([employees, more_employees], ignore_index=True)\n",
    "print(all_employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Pivot Tables and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sales data\n",
    "sales = pd.DataFrame({\n",
    "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-03'],\n",
    "    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'Region': ['North', 'North', 'South', 'South', 'North', 'South'],\n",
    "    'Sales': [100, 150, 120, 180, 110, 160]\n",
    "})\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales)\n",
    "\n",
    "# Pivot table\n",
    "print(\"\\nPivot table (Product vs Region):\")\n",
    "pivot = sales.pivot_table(values='Sales', index='Product', columns='Region', aggfunc='sum')\n",
    "print(pivot)\n",
    "\n",
    "# Melt (unpivot)\n",
    "print(\"\\nMelted pivot table:\")\n",
    "melted = pivot.reset_index().melt(id_vars='Product', var_name='Region', value_name='Total_Sales')\n",
    "print(melted)\n",
    "\n",
    "# Crosstab\n",
    "print(\"\\nCrosstab:\")\n",
    "crosstab = pd.crosstab(sales['Product'], sales['Region'], values=sales['Sales'], aggfunc='sum')\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Reading and Writing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for file operations\n",
    "sample_data = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'Salary': [50000, 60000, 55000]\n",
    "})\n",
    "\n",
    "# Write to CSV (commented out to avoid creating files)\n",
    "# sample_data.to_csv('sample_data.csv', index=False)\n",
    "# print(\"Data written to CSV\")\n",
    "\n",
    "# Read from CSV (commented out as file doesn't exist)\n",
    "# df_from_csv = pd.read_csv('sample_data.csv')\n",
    "# print(\"Data read from CSV:\")\n",
    "# print(df_from_csv)\n",
    "\n",
    "# Other file formats (examples)\n",
    "print(\"File I/O examples (commented out):\")\n",
    "print(\"# Write to Excel: df.to_excel('file.xlsx', index=False)\")\n",
    "print(\"# Read from Excel: pd.read_excel('file.xlsx')\")\n",
    "print(\"# Write to JSON: df.to_json('file.json')\")\n",
    "print(\"# Read from JSON: pd.read_json('file.json')\")\n",
    "\n",
    "# Convert to different formats\n",
    "print(\"\\nConvert to dictionary:\")\n",
    "print(sample_data.to_dict())\n",
    "\n",
    "print(\"\\nConvert to JSON string:\")\n",
    "print(sample_data.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Advanced Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions\n",
    "print(\"Apply functions:\")\n",
    "df_apply = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [10, 20, 30, 40]\n",
    "})\n",
    "\n",
    "# Apply to column\n",
    "print(\"Square of column A:\")\n",
    "print(df_apply['A'].apply(lambda x: x**2))\n",
    "\n",
    "# Apply to DataFrame\n",
    "print(\"\\nSum of each row:\")\n",
    "print(df_apply.apply(sum, axis=1))\n",
    "\n",
    "# Map values\n",
    "print(\"\\nMap values:\")\n",
    "mapping = {1: 'One', 2: 'Two', 3: 'Three', 4: 'Four'}\n",
    "print(df_apply['A'].map(mapping))\n",
    "\n",
    "# Query method\n",
    "print(\"\\nQuery method:\")\n",
    "result = df.query('Age > 28 and Salary > 50000')\n",
    "print(result)\n",
    "\n",
    "# Ranking\n",
    "print(\"\\nRank by salary:\")\n",
    "df_rank = df.copy()\n",
    "df_rank['Salary_Rank'] = df_rank['Salary'].rank(ascending=False)\n",
    "print(df_rank[['Name', 'Salary', 'Salary_Rank']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Practical Example: Sales Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive sales dataset\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n",
    "products = ['Laptop', 'Phone', 'Tablet', 'Watch']\n",
    "regions = ['North', 'South', 'East', 'West']\n",
    "\n",
    "# Generate random sales data\n",
    "n_records = 1000\n",
    "sales_analysis = pd.DataFrame({\n",
    "    'Date': np.random.choice(dates, n_records),\n",
    "    'Product': np.random.choice(products, n_records),\n",
    "    'Region': np.random.choice(regions, n_records),\n",
    "    'Quantity': np.random.randint(1, 20, n_records),\n",
    "    'Unit_Price': np.random.randint(100, 2000, n_records)\n",
    "})\n",
    "\n",
    "# Calculate total sales\n",
    "sales_analysis['Total_Sales'] = sales_analysis['Quantity'] * sales_analysis['Unit_Price']\n",
    "\n",
    "# Group by date and product\n",
    "sales_summary = sales_analysis.groupby(['Date', 'Product']).agg({'Total_Sales': 'sum', 'Quantity': 'sum'}).reset_index()\n",
    "\n",
    "# Pivot table for better visualization\n",
    "sales_pivot = sales_summary.pivot_table(values='Total_Sales', index='Date', columns='Product', fill_value=0)\n",
    "\n",
    "# Display the sales pivot table\n",
    "print(\"Sales Pivot Table:\")\n",
    "print(sales_pivot.head())\n",
    "\n",
    "# Visualize total sales over time\n",
    "import matplotlib.pyplot as plt\n",
    "sales_pivot.plot(figsize=(12, 6))\n",
    "plt.title('Total Sales Over Time by Product')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.legend(title='Product')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Find top-selling products\n",
    "top_products = sales_analysis.groupby('Product')['Total_Sales'].sum().sort_values(ascending=False).head(5)\n",
    "print(\"\\nTop 5 Selling Products:\")\n",
    "print(top_products)\n",
    "\n",
    "# Find sales by region\n",
    "sales_by_region = sales_analysis.groupby('Region')['Total_Sales'].sum().sort_values(ascending=False)\n",
    "print(\"\\nSales by Region:\")\n",
    "print(sales_by_region)\n",
    "\n",
    "# Visualize sales by region\n",
    "sales_by_region.plot(kind='bar', figsize=(8, 5))\n",
    "plt.title('Total Sales by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Analyze sales trends over time\n",
    "sales_trend = sales_analysis.groupby('Date')['Total_Sales'].sum().reset_index()\n",
    "sales_trend.set_index('Date', inplace=True)\n",
    "sales_trend.plot(figsize=(12, 6))\n",
    "plt.title('Total Sales Trend Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Find monthly sales summary\n",
    "monthly_sales = sales_analysis.resample('M', on='Date').agg({'Total_Sales': 'sum', 'Quantity': 'sum'}).reset_index()\n",
    "monthly_sales['Date'] = monthly_sales['Date'].dt.strftime('%Y-%m')\n",
    "print(\"\\nMonthly Sales Summary:\")\n",
    "print(monthly_sales)\n",
    "\n",
    "# Visualize monthly sales\n",
    "monthly_sales.plot(x='Date', y='Total_Sales', kind='bar', figsize=(12, 6))\n",
    "plt.title('Monthly Total Sales')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}